# Automated-Image-Captioning
This project is aimed at creating an end-to-end neural network system that can automatically view an image and generate reasonable description in plain English. The system is based on a pre-trained InceptionV3 model that encodes an image into a compact representation, followed by a Long Short-Term Memory (LSTM) networks that generates a
corresponding sentence using beam search algorithm. The performance of the system is tested by a metric called Bilingual Evaluation Understudy (BLEU) score.
